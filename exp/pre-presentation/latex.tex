\documentclass[a4paper]{article}
\usepackage[utf8x]{inputenc} %commentaire
\usepackage[francais]{babel} %FR
\usepackage[T1]{fontenc} 

\usepackage[pdftex]{graphicx} % img
\usepackage{wrapfig}

\usepackage{algpseudocode}


\usepackage[top=0.5cm, bottom=0.5cm, left=0.5cm, right=0.5cm]{geometry} %RÃ©duire les marges

\usepackage{layout}

\begin{document}

Formule RMS

$ rms\ proportion_{e} = \frac{ rms_{e} = \sqrt{ \frac{1}{n} \sum \limits_{i=1}^{n} ( o_{i,e} - d_{i} )^2 }}{max(rms_{e}),\ \forall e \in epochs } $

$ with \left\lbrace \begin{array}{lll} n : number\ of\ neurons\ on\ the\ output\ layer\\o_{i,e} : value\ obtained\ for\ the\ i^{th}\ neuron\ at\ the\ e^{th}\ epoch\\d_{i} : value\ desired \ for\ the\ i^{th}\ neuron\end{array} \right.$
         


\newpage


\begin{algorithmic}

\Function{discretize}{$hiddenNeuron[], piece$}
\State $result \gets 0$
\For{$i = 0 \to hiddenNeuron.length $} 
\State $result \gets result + piece^{i} \times cutting(hiddenNeuron[i], piece) $
\State $i \gets i + 1$
\EndFor
\State \Return result
\EndFunction

\end{algorithmic}

 -\\[4cm]

\begin{algorithmic}

\State $first\_order.calc\_hidden\_layer(samples.inputs)$
\State $high\_order.calc\_output\_layer(first\_order.hidden\_layer)$
\State $first\_order.calc\_output\_layer(first\_order.hidden\_layer,\ [0, ..., 0])$
\State 
\State $h\_output \gets ampli(high\_order.output\_layer)$
\State $right\_houtput \gets [0,\ 0]$
\If{$good\_answer(first\_order)$}
  \State $right\_houtput[1] \gets 1$
\Else
  \State $right\_houtput[0] \gets 1$
\EndIf
\State $first\_order.calc\_output\_layer(first\_order.hidden\_layer,\ h\_output)$
\State
\State $calc\_stats()$
\State
\State $high\_order.train(first\_order.hidden\_layer,\ right\_houtput)$
\State $first\_order.train(samples.inputs,\ samples.outputs,\ h\_output)$


\end{algorithmic}


\newpage

\begin{algorithmic}

\Function{$train$}{$inputs,\ outputs,\ add$}
\For {$i = 0 \to output\_neurons.length$}
\State $y_{output}[i] \gets g'(output\_neurons[i].a) \times ( outputs[i] - output\_neurons.state )$
\EndFor
\\
\For {$i = 0 \to hidden\_neurons.length$}
\State $w\_sum \gets \sum \limits_{j=0}^{output\_neurons.length} output\_neurons[j].weights[i] \times y_{output[j]}$
\State $y_{hidden}[i] \gets g'(hidden\_neurons[i].a) \times w\_sum$
\EndFor
\State $update\_weights\_hidden\_layer(y_{hidden})$
\\
\For {$i = 0 \to output\_neurons.length$ } 
\State $output\_neurons[i].update\_weights\_gradient(y_{output}[i],\ hidden\_neurons,\ add)$
\State $output\_neurons[i].update\_weights\_perceptron(outputs[i],\ hidden\_neurons,\ add)$
\EndFor
\EndFunction

\end{algorithmic}


\begin{algorithmic}

\Function{$update\_weights\_gradient$}{$error,\ intputs,\ add$}
\State $calc\_output(inputs + add)$
\\
\For {$j = 0 \to inputs.length$ } 
\State $dw \gets weights[j] - last\_weights[j]$
\State $p \gets error \times inputs[j]$
\State $weights[j] \gets weights[j] + learning\_rate \times p + momentum \times dw$
\EndFor
\EndFunction

\end{algorithmic}


\begin{algorithmic}

\Function{$update\_weights\_perceptron$}{$goal,\ intputs,\ add$}
\State $calc\_output(inputs + add)$
\\
\For {$j = inputs.length \to inputs.length + add.length$ } 
\State $dw \gets weights[j] - last\_weights[j]$
\State $p \gets (goal - state ) \times add[inputs.length - j]$
\State $weights[j] \gets weights[j] + \frac{learning\_rate \times p + momentum \times dw}{add.length} $
\EndFor
\EndFunction

\end{algorithmic}


\end{document}
